import os
import json
import logging
import argparse
import pandas as pd
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI
import time
from datetime import datetime
import math
import shutil

# === 1. Prompt è®¾è®¡ ===
SYSTEM_PROMPT = """You are an expert in drug repurposing. Your task is to predict whether a specific drug has any potential therapeutic effect (including off-label, investigational, or mechanistic plausibility) for a specific disease.
Respond with exactly ONE word: "Yes" or "No".
- Answer "Yes" if there is any biological rationale, clinical evidence, or shared pathway suggesting potential efficacy.
- Answer "No" only if they are completely unrelated or contraindicated.
"""

USER_PROMPT_TEMPLATE = """Target Pair:
Drug: "{drug_name}"
Disease: "{disease_name}"
"""


# === 2. å·¥å…·å‡½æ•° ===
def safe_token_match(token):
    """æå– token ä¸­è¿ç»­å­—æ¯éƒ¨åˆ†å¹¶è½¬å°å†™"""
    # æ¯”å¦‚ " Yes" -> "yes", "no!" -> "no"
    return ''.join([c for c in token if c.isalpha()]).lower()


def get_prediction_prob(client, model, drug, disease, max_retries=3, idx=None):
    """æ ¸å¿ƒé¢„æµ‹å‡½æ•°ï¼šè·å– Logprobs å¹¶ç´¯åŠ è®¡ç®— P(Yes)"""
    user_content = USER_PROMPT_TEMPLATE.format(drug_name=drug, disease_name=disease)

    for attempt in range(max_retries):
        try:
            completion = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_content},
                ],
                temperature=0.0,
                max_tokens=1,
                logprobs=True,
                top_logprobs=5,  # é˜¿é‡Œäº‘åå°ï¼Œæœ€é«˜åªèƒ½ä¸º5
                extra_body={"enable_thinking": False}
            )

            # å…¼å®¹æ€§æå–
            try:
                resp_dict = completion.model_dump()
            except AttributeError:
                resp_dict = completion.dict()

            choices = resp_dict.get("choices", [])
            if not choices:
                raise ValueError("No choices in response")

            choice = choices[0]
            message = choice.get("message", {})
            raw_content = message.get("content", "").strip()

            # è·å– Logprobs
            logprobs = message.get("logprobs")
            if not logprobs or not logprobs.get("content"):
                logprobs = choice.get("logprobs", {})  # å…¼å®¹æŸäº›éæ ‡ API

            if not logprobs or not logprobs.get("content"):
                logging.error(f"[Idx {idx}] No logprobs returned. Raw content: {raw_content}")
                return 0.0, raw_content

            token_info = logprobs["content"][0]
            top_logprobs = token_info.get("top_logprobs", [])

            # --- ğŸ”¥ å…³é”®æ”¹è¿›ï¼šæ¦‚ç‡ç´¯åŠ é€»è¾‘ ---
            # Tokenizer å¯èƒ½ä¼šæŠŠ "Yes", " yes", "YES" è§†ä¸ºä¸åŒ token
            # æˆ‘ä»¬éœ€è¦åœ¨çº¿æ€§ç©ºé—´ä¸‹ç´¯åŠ æ¦‚ç‡
            sum_prob_yes = 0.0
            sum_prob_no = 0.0

            raw_tokens_debug = []

            for t in top_logprobs:
                token_str = t.get("token", "")
                logprob_val = t.get("logprob")

                # è®°å½•ä¸€ä¸‹ç”¨äº debug
                raw_tokens_debug.append(f"{token_str}({logprob_val:.2f})")

                clean_token = safe_token_match(token_str)
                prob_linear = math.exp(logprob_val)  # è½¬å› 0-1 æ¦‚ç‡

                if clean_token == "yes":
                    sum_prob_yes += prob_linear
                elif clean_token == "no":
                    sum_prob_no += prob_linear

            # æ‰“å° Top tokens æ–¹ä¾¿è°ƒè¯•
            logging.debug(f"[Idx {idx}] Tokens: {raw_tokens_debug}")

            # å…œåº•é˜²æ­¢é™¤ä»¥é›¶ï¼ˆå¦‚æœæ¨¡å‹å›ç­”äº† "Maybe" ç­‰å®Œå…¨æ— å…³çš„è¯ï¼‰
            sum_prob_yes = max(sum_prob_yes, 1e-10)
            sum_prob_no = max(sum_prob_no, 1e-10)

            # å½’ä¸€åŒ–è®¡ç®— P(Yes)
            pred_prob_yes = sum_prob_yes / (sum_prob_yes + sum_prob_no)

            return pred_prob_yes, raw_content

        except Exception as e:
            wait_time = (2 ** attempt) * 1
            logging.warning(f"[Idx {idx}] Error (Attempt {attempt + 1}): {repr(e)}. Retrying...")
            time.sleep(wait_time)

    return 0.0, "Error"


# === 3. æ•°æ®ç”Ÿæˆå™¨ï¼ˆæµå¼è¯»å–ï¼‰ ===
def yield_input_data(file_path, limit=None):
    """
    ä¸€è¡Œä¸€è¡Œè¯»å–æ–‡ä»¶ï¼ŒèŠ‚çœå†…å­˜ã€‚
    è‡ªåŠ¨å¤„ç† csv æˆ– jsonlã€‚
    """
    count = 0
    if file_path.endswith('.csv'):
        # CSV éœ€è¦ç”¨ pandas åˆ†å—è¯»å–æˆ–è¿­ä»£å™¨ï¼Œè¿™é‡Œä¸ºäº†ç®€å•ç”¨ chunks
        # å¦‚æœæ–‡ä»¶å·¨å¤§ï¼Œå»ºè®®ç”¨ pd.read_csv(..., chunksize=1)
        for chunk in pd.read_csv(file_path, chunksize=1):
            record = chunk.iloc[0].to_dict()
            yield record
            count += 1
            if limit and count >= limit: break
    else:
        # JSONL é€è¡Œè¯»
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if not line.strip(): continue
                try:
                    yield json.loads(line)
                    count += 1
                    if limit and count >= limit: break
                except json.JSONDecodeError:
                    continue


# === 4. ä¸»ç¨‹åº ===
def main():
    parser = argparse.ArgumentParser(description="Run Qwen Logprobs (Streaming & Sorting)")
    parser.add_argument("--input_file", required=True, help="Input CSV or JSONL")
    parser.add_argument("--output_jsonl", required=True, help="Final sorted Output JSONL")
    parser.add_argument("--model", required=True, help="Model name")
    parser.add_argument("--api_key", default=os.getenv("DASHSCOPE_API_KEY"), help="API Key")
    parser.add_argument("--base_url", default="https://dashscope.aliyuncs.com/compatible-mode/v1", help="API Base URL")
    parser.add_argument("--threads", type=int, default=4, help="Concurrency level")
    parser.add_argument("--limit", type=int, default=None, help="Debug: limit number of samples (e.g. 10)")
    args = parser.parse_args()

    # --- æ—¥å¿—é…ç½® ---
    current_dir = os.path.dirname(os.path.abspath(__file__))
    logs_dir = os.path.join(current_dir, "../logs")
    os.makedirs(logs_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_path = os.path.join(logs_dir, f"run_{timestamp}.log")

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(log_path, encoding='utf-8'),
            # logging.StreamHandler()
        ]
    )

    client = OpenAI(api_key=args.api_key, base_url=args.base_url)

    # å®šä¹‰ä¸´æ—¶æ–‡ä»¶ï¼šç”¨äºå­˜å‚¨ä¹±åºç»“æœï¼ˆé˜²æ­¢ç¨‹åºä¸­æ–­æ•°æ®ä¸¢å¤±ï¼‰
    temp_output_file = args.output_jsonl + ".tmp"

    # æ¸…ç†æ—§çš„ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if os.path.exists(temp_output_file):
        os.remove(temp_output_file)

    print(f"ğŸš€ Processing: {args.input_file}")
    print(f"ğŸ“‚ Temp output: {temp_output_file} (Will be sorted later)")

    # ä»»åŠ¡å¤„ç†é€»è¾‘
    def process_item_wrapper(item, auto_idx):
        drug = item.get('drug_name') or item.get('x_name')
        disease = item.get('disease_name') or item.get('y_name')

        # å¦‚æœåŸå§‹æ•°æ®é‡Œæœ‰ labelï¼Œä¿ç•™å®ƒ
        label = item.get('label')

        if not drug or not disease:
            return None

        prob, text = get_prediction_prob(client, args.model, drug, disease, idx=auto_idx)

        return {
            "index": auto_idx,  # ä½¿ç”¨ enumerate ç”Ÿæˆçš„æœ‰åº ID (0, 1, 2...)
            "drug_name": drug,
            "disease_name": disease,
            "label": label,
            "pred_prob": prob,
            "raw_response": text
        }

    # --- ç¬¬ä¸€é˜¶æ®µï¼šå¤šçº¿ç¨‹æ‰§è¡Œ + å®æ—¶æµå¼å†™å…¥ï¼ˆä¹±åºï¼‰ ---
    total_processed = 0

    # æ‰“å¼€ä¸´æ—¶æ–‡ä»¶å¥æŸ„ï¼Œå‡†å¤‡éšæ—¶å†™å…¥
    with open(temp_output_file, 'a', encoding='utf-8') as f_out:
        with ThreadPoolExecutor(max_workers=args.threads) as executor:
            futures = []

            # 1. æäº¤ä»»åŠ¡ (Generator æµå¼è¯»å–)
            # enumerate(..., 0) ä¿è¯ ID ä» 0 å¼€å§‹
            for idx, item in enumerate(yield_input_data(args.input_file, args.limit), 0):
                future = executor.submit(process_item_wrapper, item, idx)
                futures.append(future)

            total_tasks = len(futures)
            print(f"ğŸ“¥ Tasks submitted: {total_tasks}")

            # 2. è·å–ç»“æœ (æŒ‰å®Œæˆé¡ºåº)
            for future in tqdm(as_completed(futures), total=total_tasks, desc="Progress"):
                try:
                    result = future.result()
                    if result:
                        # ç«‹å³å†™å…¥æ–‡ä»¶ï¼Œè½è¢‹ä¸ºå®‰
                        f_out.write(json.dumps(result, ensure_ascii=False) + "\n")
                        f_out.flush()  # å¼ºåˆ¶åˆ·å…¥ç£ç›˜
                        total_processed += 1
                except Exception as e:
                    logging.error(f"Critical error in thread: {e}")

    print(f"âœ… Processing complete. Raw data saved to {temp_output_file}")
    print("ğŸ”„ Sorting results by Index ID...")

    # --- ç¬¬äºŒé˜¶æ®µï¼šæ’åºå¹¶ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶ ---
    try:
        # è¯»å–ä¸´æ—¶æ–‡ä»¶æ‰€æœ‰è¡Œ
        all_results = []
        with open(temp_output_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    all_results.append(json.loads(line))

        # æŒ‰ index æ’åº
        all_results.sort(key=lambda x: x['index'])

        # å†™å…¥æœ€ç»ˆæ–‡ä»¶
        with open(args.output_jsonl, 'w', encoding='utf-8') as f:
            for item in all_results:
                f.write(json.dumps(item, ensure_ascii=False) + "\n")

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.remove(temp_output_file)
        print(f"ğŸ‰ Success! Sorted output saved to: {args.output_jsonl}")

    except Exception as e:
        print(f"âŒ Error during sorting: {e}")
        print(f"âš ï¸ Do not worry, your data is safe in {temp_output_file}")


if __name__ == "__main__":
    main()